{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51054a7a-2073-4257-ba54-906ac9bb1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb70b980-66ce-42a3-8199-1c090b59e22d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\meir_\\\\Desktop\\\\ניתוח נתוניםdataset.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmeir_\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mניתוח נתוניםdataset.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m data\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    505\u001b[0m         io,\n\u001b[0;32m    506\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    507\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    508\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    509\u001b[0m     )\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1580\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engines[engine](\n\u001b[0;32m   1581\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io,\n\u001b[0;32m   1582\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1583\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m   1584\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:553\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03mReader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;124;03m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    552\u001b[0m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 553\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    554\u001b[0m     filepath_or_buffer,\n\u001b[0;32m    555\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    556\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    557\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:572\u001b[0m, in \u001b[0;36mBaseExcelReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m    569\u001b[0m     handle\u001b[38;5;241m=\u001b[39mfilepath_or_buffer, compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m    570\u001b[0m )\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, (ExcelFile, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workbook_class)):\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m    573\u001b[0m         filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     )\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workbook_class):\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\meir_\\\\Desktop\\\\ניתוח נתוניםdataset.xlsx'"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('C:\\\\Users\\\\meir_\\\\Desktop\\\\ניתוח נתונים', engine='openpyxl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d73fa-548b-4e4e-9847-f0ccbea3bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Price'].unique()  \n",
    "# df['manufactor'].unique() # Lexsus = לקסוס\n",
    "# df['Cre_date'].unique() # להוריד ערכים לא קשורים, לשנות פורמט\n",
    "# df['Repub_date'].unique() # להוריד ערכים לא קשורים, לשנות פורמט\n",
    "# df['Pic_num'].unique() #נאן \n",
    "# df['Description'].unique() # לסדר תווים מיוחדים\n",
    "# df['Year'].unique() \n",
    "# df['Hand'].unique() \n",
    "# df['Gear'].unique() # אוטומטית = אוטומט , נאן, לא מוגדר\n",
    "# df['capacity_Engine'].unique() #נאן\n",
    "#data['Engine_type'].unique() #לשנות היבריד=היברידי, נאן \n",
    "# df['Km'].unique()  #נאן \n",
    "# df['Prev_ownership'].unique()  # אחר נאן  לא מוגדר \n",
    "# df['Curr_ownership'].unique()   # אחר נאן  לא מוגדר \n",
    "# data['Area'].unique()  \n",
    "# df['City'].unique() \n",
    "# df['Test'].unique() # מינוס ,  להוריד ערכים לא קשורים, לשנות פורמט, נאן\n",
    "# df['Supply_score'].unique() #נאן\n",
    "data['Color'].unique()# לאחד צבעים, נאן"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2ff45-4444-411a-938d-ac2b46de9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Cre_date']= pd.to_datetime(df['Cre_date'],format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf632dcd-a4f1-49de-934e-f506cee7c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#עמודת עיר\n",
    "replacements_city = {\n",
    "    'אבן': 'אבן יהודה',\n",
    "    'מושבים': 'מושבים בשרון',\n",
    "    'בית ג׳אן': 'בית ג׳ן',\n",
    "    'בת': 'בת ים',\n",
    "    'גבעתי': 'גבעתיים',\n",
    "    'גבעתיי': 'גבעתיים',\n",
    "    'הוד': 'הוד השרון',\n",
    "    'חד': 'חד נס',\n",
    "    'טייבה': 'טייבה משולש',\n",
    "    'טירת הכרמל': 'טירת כרמל',\n",
    "    'יהוד': 'יהוד מונסון',\n",
    "    'יוקנעם': 'יוקנעם עילית',\n",
    "    'יוקנעם עילית': 'יקנעם עילית',\n",
    "    'כפר': 'כפר סבא',\n",
    "    'מודיעין': 'מודיעין מכבים רעות',\n",
    "    'מעלות': 'מעלות תרשיחא',\n",
    "    'נהרייה': 'נהריה',\n",
    "    'נוף הגליל': 'נצרת עילית',\n",
    "    'נתנייה': 'נתניה',\n",
    "    'פתח': 'פתח תקווה',\n",
    "    'פתח תיקווה': 'פתח תקווה',\n",
    "    'פרדס': 'פרדס חנה כרכור',\n",
    "    'ק.אתא': 'קריית אתא',\n",
    "    'קרית אתא': 'קריית אתא',\n",
    "    'קרית': 'קריות',\n",
    "    'קרית ביאליק': 'קריית ביאליק',\n",
    "    'קרית טבעון': 'קריית טבעון',\n",
    "    'קרית ים': 'קריית ים',\n",
    "    'רא': 'ראש העין',\n",
    "    'ראש': 'ראש העין',\n",
    "    'ראשון': 'ראשון לציון',\n",
    "    'תל אבייב': 'תל אביב יפו',\n",
    "    'תל': 'תל אביב יפו',\n",
    "    'jeruslem': 'ירושלים',\n",
    "    'Rehovot': 'רחובות',\n",
    "    'Rishon LeTsiyon': 'ראשון לציון',\n",
    "    'haifa': 'חיפה',\n",
    "    'p': 'פתח תקווה',\n",
    "    'Tel aviv': 'תל אביב יפו',\n",
    "    'ashdod': 'אשדוד',\n",
    "    'Tel Aviv': 'תל אביב יפו',\n",
    "    \"חיפ\" : \"חיפה\",    \n",
    "}\n",
    "\n",
    "data['City'] = data['City'].replace(replacements_city)\n",
    "data['City'].replace({'פ\"ת' :'פתח תקווה'}, inplace=True)\n",
    "data['City'].replace({'פתח תקווה,יהוד' :'פתח תקווה'}, inplace=True)\n",
    "data['City'].replace({'Tzur Natan' :'צור נתן'}, inplace=True)\n",
    "\n",
    "#עמודת אזור\n",
    "replacements_area = {\n",
    "    'ירושלים': 'ירושלים והסביבה',\n",
    "    'גליל': 'גליל והעמקים',\n",
    "    'עמק': 'גליל והעמקים',\n",
    "    'פרדס': 'פרדס חנה - כרכור',\n",
    "    'אזור השרון והסביבה': 'רמת השרון - הרצליה',\n",
    "    'מושבים בשרון': 'רמת השרון - הרצליה',\n",
    "    'הוד השרון והסביבה': 'רמת השרון - הרצליה',\n",
    "    'מושבים': 'רמת השרון - הרצליה',\n",
    "    'הוד': 'רמת השרון - הרצליה',\n",
    "    'רמת': 'רמת השרון - הרצליה',\n",
    "    'טבריה': 'טבריה והסביבה',\n",
    "    'פתח': 'פתח תקווה והסביבה',\n",
    "    'פתח תקוה והסביבה': 'פתח תקווה והסביבה',\n",
    "    'נתניה': 'נתניה והסביבה',\n",
    "    'רמלה': 'רמלה - לוד',\n",
    "    'נס': 'נס ציונה - רחובות',\n",
    "    'רחובות': 'נס ציונה - רחובות',\n",
    "    'ראשלצ': 'ראשלצ והסביבה',\n",
    "    'ראש': 'ראשלצ והסביבה',\n",
    "    'ראשל\"צ והסביבה': 'ראשלצ והסביבה',\n",
    "    'ראשל\"צ': 'ראשלצ והסביבה',\n",
    "    'גליל ועמקים': 'גליל והעמקים',\n",
    "    'תל אביב יפו': 'תל אביב',\n",
    "    'תל': 'תל אביב',\n",
    "    'חולון': 'חולון - בת ים',\n",
    "    'רעננה': 'רעננה - כפר סבא',\n",
    "    'מודיעין': 'מודיעין והסביבה',\n",
    "    'חיפה': 'חיפה וחוף הכרמל',\n",
    "\n",
    "}\n",
    "\n",
    "data['Area'] = data['Area'].replace(replacements_area)\n",
    "data['Area'].unique()\n",
    "\n",
    "#עמודת גיר\n",
    "data['Gear'].replace({'טיפטרוניק' :'אוטומט'}, inplace=True)\n",
    "data['Gear'].replace({'רובוטית' :'אוטומט'}, inplace=True)\n",
    "data['Gear'].replace({'אוטומטית' :'אוטומט'}, inplace=True)\n",
    "\n",
    "#עמודת סוג מנוע\n",
    "data['Engine_type'].replace({'היבריד' :'היברידי'}, inplace=True)\n",
    "\n",
    "#עמודת צבעים\n",
    "data['Color'] = data['Color'].apply(lambda x: ',כחול,' if pd.notnull(x) and re.search(r'\\bכחול\\b', x, re.IGNORECASE) else x)\n",
    "\n",
    "# #עמודות בעלות\n",
    "# data['Prev_ownership'].replace({'ליסינג' :'השכרה'}, inplace=True)\n",
    "# data['Curr_ownership'].replace({'ליסינג' :'השכרה'}, inplace=True)\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6729beb-1017-4ea7-bdfd-aadd4b3e466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#טיפול בערכים בעייתיים\n",
    "data['manufactor'].replace({'Lexsus' :'לקסוס'}, inplace=True)\n",
    "# data['engine_type'].replace({'היבריד' :'היברידי'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfee4e1-4f95-4091-b3cf-cc73e8fce6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78d71d-0cc1-46d4-9bd8-dc2d566b2ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_data(data):\n",
    "#     data.loc[:, 'price'] = pd.to_numeric(data['price'], errors='coerce')\n",
    "#     data.dropna(subset=['price'], inplace=True)\n",
    "#     data.loc[:, 'Area'] = pd.to_numeric(data['Area'], errors='coerce')\n",
    "\n",
    "#     data['price'] = data['price'].replace('[^0-9]', '', regex=True)\n",
    "#     data['type'] = data['type'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['Street'] = data['Street'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['city_area'] = data['city_area'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['description '] = data['description '].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['Area'] = data['Area'].replace('[^0-9]', '', regex=True)\n",
    "#     data['room_number'] = data['room_number'].replace('[^0-9]', '', regex=True)\n",
    "\n",
    "#     data['floor'] = data['floor_out_of'].str.split().str[1]\n",
    "#     data['total_floors'] = data['floor_out_of'].str.split().str[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d31841-1865-419a-89fc-70119c4fe92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_car_data(data):\n",
    "    # המרת עמודות למספרים ולטיפול בערכים חסרים\n",
    "    data['Price'] = pd.to_numeric(data['Price'].replace('[\\$,₪]', '', regex=True), errors='coerce') # מוריד תווים מיוחדים והמרה לערכים מספריים \n",
    "    data['Km'] = pd.to_numeric(data['Km'].replace('[\\,]', '', regex=True), errors='coerce') # מוריד תווים מיוחדים והמרה לערכים מספריים \n",
    "    data['capacity_Engine'] = pd.to_numeric(data['capacity_Engine'].replace('[\\,]', '', regex=True), errors='coerce')# מוריד תווים מיוחדים והמרה לערכים מספריים \n",
    "\n",
    "    #  מילוי הערכים החסרים בערך הנפוץ בעמודת נפח מנוע \n",
    "    engine_capacity_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    data[['capacity_Engine']] = engine_capacity_imputer.fit_transform(data[['capacity_Engine']]) \n",
    "\n",
    "    #בגלל שמטרת המודל היא לחזות מחיר, נוריד את השורות שבהן לא צויין מחיר\n",
    "    data.dropna(subset=['Price'], inplace=True)\n",
    "\n",
    "    #מילוי הערכים החסרים בממוצע בעמודת ק\"מ, לפי יד ושנה    \n",
    "    average_km = data.groupby(['Year', 'Hand'])['Km'].mean()\n",
    "    data['Km'] = data.apply(lambda row: average_km[row['Year'], row['Hand']] if pd.isnull(row['Km']) else row['Km'], axis=1)\n",
    "\n",
    "    # מחיקת השורות עם ערכים חסרים בעמודת ה-KM\n",
    "    data.dropna(subset=['Km'], inplace=True)\n",
    "\n",
    "#עמודת גיר ערכי נאן ולא מוגדר למחוק\n",
    "\n",
    "#     # ניקוי ערכים קטגוריאליים\n",
    "#     data['manufactor'] = data['manufactor'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['model'] = data['model'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['Engine_type'] = data['Engine_type'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['Area'] = data['Area'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['City'] = data['City'].replace('[^\\w\\s]', '', regex=True)\n",
    "    \n",
    "#     # המרת ערכים קטגוריאליים ל-one-hot encoding\n",
    "#     data = pd.get_dummies(data, columns=['manufactor', 'model', 'Engine_type', 'Area', 'City'], drop_first=True)\n",
    "    \n",
    "#     # המרת ערכים בינאריים למספרים\n",
    "#     data['Gear'] = data['Gear'].map({'אוטומטית': 1, 'ידנית': 0, 'טיפטרוניק': 2})\n",
    "#     data['Prev_ownership'] = data['Prev_ownership'].map({'פרטית': 1, 'ליסינג': 0})\n",
    "#     data['Curr_ownership'] = data['Curr_ownership'].map({'פרטית': 1, 'ליסינג': 0})\n",
    "    \n",
    "#     # המרת עמודות לתאריכים\n",
    "#     data['Cre_date'] = pd.to_datetime(data['Cre_date'], errors='coerce')\n",
    "#     data['Repub_date'] = pd.to_datetime(data['Repub_date'], errors='coerce')\n",
    "    \n",
    "#     return data\n",
    "\n",
    "# # ניקוי הדאטה\n",
    "# cleaned_data = prepare_car_data(data)\n",
    "\n",
    "# # הצגת השורות הראשונות לאחר הניקוי\n",
    "# cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e793097-d9e8-441d-9142-c11c09e2442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # חלוקה לקבוצות קטנות יותר\n",
    "# columns = cleaned_data.columns.tolist()\n",
    "# num_columns = len(columns)\n",
    "# chunk_size = 20  # הצגת כל 20 עמודות בכל קבוצה\n",
    "\n",
    "# for i in range(0, num_columns, chunk_size):\n",
    "#     print(columns[i:i + chunk_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193dafe-e247-4cfb-8132-d7002c4311e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "\n",
    "# # קריאת הדאטה\n",
    "# data = pd.read_excel('C:\\\\Users\\\\meir_\\\\Desktop\\\\ניתוח נתונים\\\\dataset.xlsx', engine='openpyxl')\n",
    "\n",
    "# # הכנת הדאטה\n",
    "# def prepare_car_data(data):\n",
    "#     data['Price'] = pd.to_numeric(data['Price'].replace('[\\$,]', '', regex=True), errors='coerce')\n",
    "#     data['Km'] = pd.to_numeric(data['Km'].replace('[\\,]', '', regex=True), errors='coerce')\n",
    "#     data['capacity_Engine'] = pd.to_numeric(data['capacity_Engine'], errors='coerce')\n",
    "#     data.dropna(subset=['Price', 'Km', 'capacity_Engine'], inplace=True)\n",
    "#     data['manufactor'] = data['manufactor'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['model'] = data['model'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['Engine_type'] = data['Engine_type'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['Area'] = data['Area'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data['City'] = data['City'].replace('[^\\w\\s]', '', regex=True)\n",
    "#     data = pd.get_dummies(data, columns=['manufactor', 'model', 'Engine_type', 'Area', 'City'], drop_first=True)\n",
    "#     data['Gear'] = data['Gear'].map({'אוטומטית': 1, 'ידנית': 0, 'טיפטרוניק': 2})\n",
    "#     data['Prev_ownership'] = data['Prev_ownership'].map({'פרטית': 1, 'ליסינג': 0})\n",
    "#     data['Curr_ownership'] = data['Curr_ownership'].map({'פרטית': 1, 'ליסינג': 0})\n",
    "#     data['Cre_date'] = pd.to_datetime(data['Cre_date'], errors='coerce')\n",
    "#     data['Repub_date'] = pd.to_datetime(data['Repub_date'], errors='coerce')\n",
    "#     if 'Test' in data.columns:\n",
    "#         data['Test'] = pd.to_datetime(data['Test'], errors='coerce')\n",
    "#     return data\n",
    "\n",
    "# # ניקוי הדאטה\n",
    "# data = prepare_car_data(data)\n",
    "\n",
    "# # בחירת מאפיינים\n",
    "# selected_features = ['Year', 'Hand', 'Gear', 'Km', 'capacity_Engine', 'Prev_ownership', 'Curr_ownership'] + \\\n",
    "#                     [col for col in data.columns if col.startswith('manufactor_') or col.startswith('model_') or \\\n",
    "#                      col.startswith('Engine_type_') or col.startswith('Area_') or col.startswith('City_')]\n",
    "\n",
    "# # חלוקת הדאטה לתכונות ויעד\n",
    "# X = data[selected_features]\n",
    "# y = data['Price']\n",
    "\n",
    "# # חלוקת הדאטה למערכי אימון ובדיקה\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# # הגדרת עמודות מספריות וקטגוריאליות\n",
    "# num_cols = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n",
    "# cat_cols = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n",
    "\n",
    "# X_train[cat_cols] = X_train[cat_cols].astype(str)\n",
    "\n",
    "# # הגדרת צינור עיבוד עבור עמודות מספריות\n",
    "# numerical_pipeline = Pipeline([\n",
    "#     ('numerical_imputation', SimpleImputer(strategy='median', add_indicator=False)),\n",
    "#     ('scaling', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# # הגדרת צינור עיבוד עבור עמודות קטגוריאליות\n",
    "# categorical_pipeline = Pipeline([\n",
    "#     ('categorical_imputation', SimpleImputer(strategy='constant', add_indicator=False, fill_value='missing')),\n",
    "#     ('one_hot_encoding', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# # הגדרת הממיר העמודות\n",
    "# column_transformer = ColumnTransformer([\n",
    "#     ('numerical_preprocessing', numerical_pipeline, num_cols),\n",
    "#     ('categorical_preprocessing', categorical_pipeline, cat_cols)\n",
    "# ], remainder='passthrough')\n",
    "\n",
    "# # בניית הצינור המשלב את העיבוד המוקדם עם המודל ElasticNet\n",
    "# pipe_preprocessing_model = Pipeline([\n",
    "#     ('preprocessing_step', column_transformer),\n",
    "#     ('model', ElasticNet(alpha=0.1))  # ניתן לשנות את ערך alpha כאן\n",
    "# ])\n",
    "\n",
    "# # ביצוע קרוס-ולידציה של 10 קיפולים להערכת המודל\n",
    "# cv_scores = cross_val_score(pipe_preprocessing_model, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "# mse_scores = -cv_scores\n",
    "# mean_mse = mse_scores.mean()\n",
    "\n",
    "# r2_scores = cross_val_score(pipe_preprocessing_model, X_train, y_train, cv=10, scoring='r2')\n",
    "\n",
    "# average_mse = mse_scores.mean()\n",
    "# average_r2 = r2_scores.mean()\n",
    "# rmse = np.sqrt(average_mse)\n",
    "\n",
    "# # אימון המודל על הדאטה של האימון\n",
    "# pipe_preprocessing_model.fit(X_train, y_train)\n",
    "\n",
    "# # תחזית על הדאטה של הבדיקה\n",
    "# y_pred = pipe_preprocessing_model.predict(X_test)\n",
    "\n",
    "# # חישוב המדדים\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(\"Training Set:\")\n",
    "# print('Mean Squared Error:', mean_mse)\n",
    "# print(\" R^2:\", average_r2)\n",
    "# print(\"RMSE:\", rmse)\n",
    "# print(\"\\nTest Set:\")\n",
    "# print(\"MSE:\", mse)\n",
    "# print(\"R^2:\", r2)\n",
    "\n",
    "# # שמירת המודל המאומן לקובץ\n",
    "# with open('trained_model.pkl', 'wb') as file:\n",
    "#     pickle.dump(pipe_preprocessing_model, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
